# -*- coding: mbcs -*-

###################################################
###                                             ###
### Approche fiabiliste - Assemblages boulonnés ###
###                                             ###
###################################################

# Bibliothèques :
import openturns as ot
import os as os
import numpy as np
import pylab as plb
import sys
from openturns import viewer
import copy as cp
import matplotlib.patches as mpatches
import scipy.stats as stats



#########################
### Données d'entrées ###
#########################

# Paramètres :
IT = 0.1	#Interval de tolérance en mm
IT0 = str(int(IT*100))
N = 1000

saveout = sys.stdout
fsock = open('CONVERGENCE/IT'+IT0+'_PC_RESULT_'+str(N)+'.txt', 'w')
sys.stdout = fsock

# Paramètres incertains :
dim = 16
# Position du centre de chaque perçage :
mu_Dx = 0.
sigma_Dx = IT/6
mu_Dy = mu_Dx
sigma_Dy = sigma_Dx

distribution_Dx1 = ot.Normal(mu_Dx, sigma_Dx)
distribution_Dx2 = ot.Normal(mu_Dx, sigma_Dx)
distribution_Dx3 = ot.Normal(mu_Dx, sigma_Dx)
distribution_Dx4 = ot.Normal(mu_Dx, sigma_Dx)

distribution_Dy1 = ot.Normal(mu_Dy, sigma_Dy)
distribution_Dy2 = ot.Normal(mu_Dy, sigma_Dy)
distribution_Dy3 = ot.Normal(mu_Dy, sigma_Dy)
distribution_Dy4 = ot.Normal(mu_Dy, sigma_Dy)

# Jeux :
Jmin = IT/2
Delta_J = 0.06
Jmax = Jmin+Delta_J
mu_J = Jmin+Delta_J/2
sigma_J = Delta_J/6

distribution_J1 = ot.Normal(mu_J, sigma_J)
distribution_J2 = ot.Normal(mu_J, sigma_J)
distribution_J3 = ot.Normal(mu_J, sigma_J)
distribution_J4 = ot.Normal(mu_J, sigma_J)

# Précharge : 
Delta_P = 0.025
mu_P = 0.045
sigma_P = Delta_P/6

distribution_P1 = ot.Normal(mu_P, sigma_P)
distribution_P2 = ot.Normal(mu_P, sigma_P)
distribution_P3 = ot.Normal(mu_P, sigma_P)
distribution_P4 = ot.Normal(mu_P, sigma_P)


# Création de la collection des distributions d'entrées
myCollection = ot.DistributionCollection(dim)
myCollection[0] = distribution_Dx1
myCollection[1] = distribution_Dx2
myCollection[2] = distribution_Dx3
myCollection[3] = distribution_Dx4
myCollection[4] = distribution_Dy1
myCollection[5] = distribution_Dy2
myCollection[6] = distribution_Dy3
myCollection[7] = distribution_Dy4
myCollection[8] = distribution_J1
myCollection[9] = distribution_J2
myCollection[10] = distribution_J3
myCollection[11] = distribution_J4
myCollection[12] = distribution_P1
myCollection[13] = distribution_P2
myCollection[14] = distribution_P3
myCollection[15] = distribution_P4

# Création d'une distribution ? en fonction de la collection
myDistribution = ot.ComposedDistribution(myCollection)
# ???
vectX = ot.RandomVector(myDistribution)


# Génération du plan d'expériences


# Lecture des résultats
file_Result = open('CONVERGENCE/IT'+IT0+'_RESULT_'+str(N)+'.txt',"r")
file_Result.readline()
Data = ot.NumericalSample(1,16)
Result = ot.NumericalSample(1,1)
for i in range(1,N+1):
	ligne = file_Result.readline().split()
	Dx1 = float(ligne[1])
	Dx2 = float(ligne[2])
	Dx3 = float(ligne[3])
	Dx4 = float(ligne[4])
	Dy1 = float(ligne[5])
	Dy2 = float(ligne[6])
	Dy3 = float(ligne[7])
	Dy4 = float(ligne[8])
	J1 = float(ligne[9])
	J2 = float(ligne[10])
	J3 = float(ligne[11])
	J4 = float(ligne[12])
	I1 = float(ligne[13])
	I2 = float(ligne[14])
	I3 = float(ligne[15])
	I4 = float(ligne[16])
	Data.add([Dx1, Dx2, Dx3, Dx4, Dy1, Dy2, Dy3, Dy4, J1, J2, J3, J4, I1, I2, I3, I4])
	f = float(ligne[21])
	Result.add([f])

file_Result.close()
Data.erase(0)
Result.erase(0)


########################
### Chaos Polynomial ###
########################

polyColl = ot.PolynomialFamilyCollection(dim)
for i in range(dim):
	polyColl[i] = ot.HermiteFactory()

enumerateFunction = ot.LinearEnumerateFunction(dim)
multivariateBasis = ot.OrthogonalProductPolynomialFactory(polyColl, enumerateFunction)

basisSequenceFactory = ot.LARS()
fittingAlgorithm = ot.CorrectedLeaveOneOut()
approximationAlgorithm = ot.LeastSquaresMetaModelSelectionFactory(basisSequenceFactory, fittingAlgorithm)

evalStrategy = ot.LeastSquaresStrategy(Data, Result,  approximationAlgorithm)

order = 3
P = enumerateFunction.getStrataCumulatedCardinal(order)
truncatureBasisStrategy = ot.FixedStrategy(multivariateBasis, P)

polynomialChaosAlgorithm = ot.FunctionalChaosAlgorithm(Data, Result, ot.Distribution(myDistribution), truncatureBasisStrategy, evalStrategy)

polynomialChaosAlgorithm.run()

The_Result = polynomialChaosAlgorithm.getResult()
Error = The_Result.getRelativeErrors()

ChaosRV = ot.FunctionalChaosRandomVector(The_Result)
Mean = ChaosRV.getMean()[0]
StD = np.sqrt(ChaosRV.getCovariance()[0,0])

print("")
print("Response mean : ", Mean)
print("")
print("Response standard deviation : ", StD)
print("")
print("Relative Error : ", Error)
print("")

meta_model = The_Result.getMetaModel()

# print("")
# print("Meta_model description = ",meta_model.getEvaluation())
# print("")

##################################
### Exploitation des résultats ###
##################################

samplesize = 10000
sample_X = vectX.getSample(samplesize)
sample_Y = meta_model(sample_X)
sample_YF = (sample_Y-7553.)*100/7553.
print(sample_Y)
asample_Y = np.array(sample_Y).flatten()
asample_YF = (asample_Y-7553.)*100/7553.

Q90_SS = stats.scoreatpercentile(asample_YF,90)
Q99_SS = stats.scoreatpercentile(asample_YF,99)
print("")
print("Q90_SS = ",Q90_SS)
print("")
print("Q99_SS = ",Q99_SS)
print("")

mean_sample = sample_Y.computeMean()[0]
standardDeviation_sample = np.sqrt(sample_Y.computeCovariance()[0,0])

# for i in range(N-1):
	# print(format(str('{0:.3f}'.format(asample_Y[i]))))

################
### Loi Beta ###
################

fittedRes = ot.BetaFactory().buildEstimator(sample_YF)
Beta =  fittedRes.getDistribution()
Beta_PDF = Beta.drawPDF(-10.,55.,251)
Beta_PDF.setLegends('PC meta-modele : '+str(N)+' realisations')
Beta_draw = Beta_PDF.getDrawable(0)
Beta_draw.setLegend('PC meta-modele : '+str(N)+' realisations')
viewer.View(Beta_draw)

Mean_Beta = Beta.getMean()
Q90_Beta = Beta.computeQuantile(0.90)
Q99_Beta = Beta.computeQuantile(0.99)

print("")
print("Mean_Beta = ",Mean_Beta)
print("")
print("Q90_Beta = ",Q90_Beta)
print("")
print("Q99_Beta = ",Q99_Beta)
print("")
print("Paramètre de la loi Beta = ",Beta.getParameter())
print("")


ResultF = (Result-7553.)*100/7553.
Q90_SS1 = stats.scoreatpercentile(ResultF,90)
Q99_SS1 = stats.scoreatpercentile(ResultF,99)
print("")
print("Q90_SS1 = ",Q90_SS1)
print("")
print("Q99_SS1 = ",Q99_SS1)
print("")

fittedRes1 = ot.BetaFactory().buildEstimator(ResultF)
Beta1 =  fittedRes1.getDistribution()
Mean_Beta1 = Beta1.getMean()
Q90_Beta1 = Beta1.computeQuantile(0.90)
Q99_Beta1 = Beta1.computeQuantile(0.99)

print("")
print("Mean_Beta1 = ",Mean_Beta1)
print("")
print("Q90_Beta1 = ",Q90_Beta1)
print("")
print("Q99_Beta1 = ",Q99_Beta1)
print("")
print("Paramètre de la loi Beta = ",Beta1.getParameter())
print("")

Sample_B = Beta.getSample(samplesize)
aSample_B = np.array(Sample_B).flatten()
# for i in range(samplesize-1):
	# print(format(str('{0:.3f}'.format(aSample_B[i]))))


plb.figure(1)
plb.hist(aSample_B, normed=True, bins=np.floor(np.sqrt(samplesize)), alpha=0.7, label='Tirages_meta-modele')
plb.xlabel('Yf[%]')
plb.ylabel('Densite de probabilite')
plb.title = ('IT'+IT0+'_COMPARAISON_Hist_Loi')
red_patch = mpatches.Patch(color='red', label='Loi Beta')
plb.legend(handles=[red_patch])
plb.legend(loc='upper right')
plb.savefig('CONVERGENCE/IT'+IT0+'_RESULT_PROBABILITY_'+str(N)+'.png')


sys.stdout = saveout
fsock.close()